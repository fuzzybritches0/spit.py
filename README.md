# spit.py

![spit.py logo](./assets/images/logo.png)

This is still work in progress.

What works:

- saving configurations
- using `/v1/chat/completions` endpoints
- Markdown
- LaTex math rendering (only tested in Kitty Terminal Emulator (no ssh) and Foot Terminal Emulator (ssh too))
- long replies (no TUI freeze, fully async)
- ...

What does not work:

- using llama.cpp server `/completion` endpoint (CPU optimised inference with KV caching)
- using llama.cpp python bindings as endpoint (CPU optimized inference with KV caching)
- tool calling
- saving and choosing between more than one chat
- saving and choosing between more than one system prompt
- graphical UI
- ...

# Instructions:

- (work in progress) ...
